{% extends "admin/base.html" %}

{% block title %}Help & Credits{% endblock %}

{% block header_title %}Help & Credits{% endblock %}

{% block content %}
<style>
    .toc-link {
        display: block;
        padding: 0.5rem 1rem;
        border-radius: 0.375rem;
        transition: all 0.2s ease-in-out;
        border-left: 3px solid transparent;
    }
    .toc-link:hover {
        background-color: rgba(128, 128, 128, 0.1);
        padding-left: 1.25rem;
    }
    .toc-link.active-toc {
        color: var(--color-primary-500);
        font-weight: 600;
        border-left-color: var(--color-primary-500);
    }
    .ui-brutalism .toc-link.active-toc {
        background-color: var(--color-primary-500);
        color: white;
        border: 3px solid black;
    }
</style>

<div class="flex flex-col lg:flex-row gap-12">

    <!-- Main Content -->
    <div class="w-full lg:w-3/4 space-y-12">

        <!-- Getting Started Workflow -->
        <div id="getting-started" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üöÄ Getting Started: Your Workflow</h2>
            <div class="space-y-4 text-current">
                <ol class="list-decimal list-inside space-y-4">
                    <li>
                        <strong>Configure Servers:</strong> Go to the <a href="{{ url_for('admin_servers') }}" class="font-semibold text-[var(--color-primary-600)] hover:underline">Server Management</a> page. Add the URLs for all your backend instances (both Ollama and vLLM are supported).
                    </li>
                    <li>
                        <strong>Create a User:</strong> Navigate to the <a href="{{ url_for('admin_users') }}" class="font-semibold text-[var(--color-primary-600)] hover:underline">User Management</a> page. This is where you'll create accounts for your users or applications.
                    </li>
                    <li>
                        <strong>Generate an API Key:</strong> From the user list, click "Manage Keys" for a specific user. On their details page, you can generate new keys and set optional, per-key rate limits (requires Redis).
                    </li>
                    <li>
                        <strong>Copy the Key:</strong> The full API key is shown **only once** upon creation. Copy it immediately and store it in a secure location like a password manager.
                    </li>
                    <li>
                        <strong>Use the Key:</strong> In your applications, replace your Ollama URL with the proxy's URL (e.g., <code class="inline-code">http://127.0.0.1:8080</code>) and provide the API key in the <code class="inline-code">Authorization</code> header as a Bearer token.
                    </li>
                </ol>
            </div>
        </div>

        <!-- Dashboard Section -->
        <div id="dashboard" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üñ•Ô∏è The Dashboard: Your Monitoring Hub</h2>
            <div class="space-y-4 text-current">
                <p>The main dashboard provides a real-time, auto-updating overview of your entire AI infrastructure.</p>
                <ul class="list-disc list-inside space-y-3 pl-4">
                    <li><strong>System Status:</strong> These gauges show the live CPU, Memory, and Disk usage of the machine running the proxy server itself.</li>
                    <li><strong>Active Models:</strong> This table shows a unified list of all models currently active across your backend servers.
                        <ul class="list-['-_'] list-inside pl-4 mt-2">
                            <li>For **Ollama** servers, this means models currently loaded into VRAM/RAM. They have an "Expires In" timer and can be unloaded.</li>
                            <li>For **vLLM** servers, all available models are considered "Always Active" as they are managed by the vLLM instance itself.</li>
                        </ul>
                    </li>
                    <li><strong>Load Balancer Status:</strong> This panel shows the health of all configured backend servers. "Online" means the proxy can reach the server, while "Offline" indicates a connection issue. It also shows a lifetime request count for each server.</li>
                    <li><strong>Rate Limit Queue Status:</strong> If you're using Redis, this shows a live view of API keys that are actively being rate-limited, how close they are to their limit, and when their usage window will reset.</li>
                </ul>
            </div>
        </div>
        
        <!-- Server Management Section -->
        <div id="server-management" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üîß Server Management</h2>
            <div class="space-y-4 text-current">
                <p>This is where you configure the backend AI servers that the proxy will manage and distribute requests to.</p>
                <ul class="list-disc list-inside space-y-3 pl-4">
                    <li><strong>Adding Servers:</strong> You can add multiple types of servers:
                        <ul class="list-['-_'] list-inside pl-4 mt-2">
                            <li><strong>Ollama:</strong> Standard Ollama instances running locally or remotely.</li>
                            <li><strong>vLLM:</strong> Any OpenAI-compatible server (vLLM, TGI, etc.). The proxy handles translation automatically.</li>
                            <li><strong>OpenRouter:</strong> Connect to OpenRouter API to access 300+ models from various providers. Requires an OpenRouter API key. Models are automatically fetched and can be enabled/disabled individually.</li>
                        </ul>
                        You can add an optional API key if your backend server requires one. For OpenRouter servers, the API key is required and is stored encrypted.
                    </li>
                    <li><strong>Refreshing Models:</strong> Clicking "Refresh" fetches the latest list of available models from a server and stores it in the proxy's database. This is crucial for the "Auto-Routing" feature. Model lists are also refreshed automatically in the background. For OpenRouter servers, this fetches all available models (free and paid) and checks their endpoint availability.</li>
                    <li><strong>Managing Models:</strong> Clicking "Manage Models" takes you to a detailed view for that server. For Ollama servers, you can pull new models, update existing ones, delete models from disk, and trigger a model to be loaded into or unloaded from memory. For OpenRouter servers, you can enable/disable specific models. These actions are not applicable to vLLM servers.</li>
                    <li><strong>OpenRouter Credits:</strong> When you have OpenRouter servers configured, the Chat Playground displays your account credits (total, used, and remaining) in real-time. This helps you monitor your usage and budget.</li>
                </ul>
            </div>
        </div>
        
        <!-- Models Manager & Auto-Routing Section -->
        <div id="models-manager" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">ü§ñ Models Manager & Auto-Routing</h2>
            <div class="space-y-6 text-current">
                <p>The Models Manager is a powerful feature that enables intelligent automatic model selection. When users request the model named <code class="inline-code">"auto"</code>, the proxy analyzes their request and routes it to the best-suited model based on capabilities, priorities, and request characteristics.</p>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">How Auto-Routing Works</h3>
                    <p>When a request comes in for the <code class="inline-code">"auto"</code> model, the system:</p>
                    <ol class="list-decimal list-inside space-y-2 mt-2 pl-4">
                        <li><strong>Analyzes the Request:</strong> Detects if the request needs images, code generation, tool calling, internet access, thinking capabilities, or fast responses.</li>
                        <li><strong>Filters by Capabilities:</strong> Only considers models that have the required capabilities enabled (e.g., if the request contains an image, only models marked "Supports Images" are considered).</li>
                        <li><strong>Applies Priority Mode:</strong> Uses your selected priority mode (Free, Daily Drive, Advanced, or Luxury) to filter models by cost and quality.</li>
                        <li><strong>Scores Models:</strong> Each eligible model receives a score based on how well it matches the request characteristics, its description, and pricing.</li>
                        <li><strong>Selects Best Model:</strong> Chooses the model with the highest score and lowest priority number.</li>
                        <li><strong>Automatic Fallback:</strong> If the selected model fails (e.g., no endpoints, 404 error), the system automatically tries the next best model until one succeeds or all are exhausted.</li>
                    </ol>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Configuring Model Capabilities</h3>
                    <p>In the <a href="{{ url_for('admin_models_manager') }}" class="font-semibold text-[var(--color-primary-600)] hover:underline">Models Manager</a> page, you can configure each model's capabilities:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li><strong>Supports Images:</strong> Enable for vision models that can process images.</li>
                        <li><strong>Code Model:</strong> Enable for models optimized for code generation and understanding.</li>
                        <li><strong>Fast Model:</strong> Enable for models optimized for speed (lower latency).</li>
                        <li><strong>Tool Calling:</strong> Enable for models that support function calling and tool use.</li>
                        <li><strong>Internet:</strong> Enable for models that can access the web or use web search.</li>
                        <li><strong>Thinking:</strong> Enable for models that support extended reasoning or chain-of-thought.</li>
                    </ul>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Priority Modes</h3>
                    <p>You can configure auto-routing to prioritize different types of models:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li><strong>üÜì Free Mode:</strong> Prioritizes free models (e.g., Grok, Llama 3.2, etc.). Best for testing and development.</li>
                        <li><strong>üöó Daily Drive Mode:</strong> Balances cost and quality. Uses affordable models for most tasks, premium models only when needed.</li>
                        <li><strong>‚ö° Advanced Mode:</strong> Prioritizes high-quality models with advanced capabilities. Good for production workloads.</li>
                        <li><strong>üíé Luxury Mode:</strong> Uses the best available models regardless of cost. For critical applications requiring top performance.</li>
                    </ul>
                    <p class="mt-2">You can use the "Auto-Priority Inventory" button to automatically calculate priorities for all models based on the selected mode.</p>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Model Priority Numbers</h3>
                    <p>Each model has a priority number (1-10, where 1 is highest priority). When multiple models have the same score, the one with the lower priority number is selected. You can manually adjust priorities in the Models Manager table.</p>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Using Auto-Routing</h3>
                    <p>To use auto-routing, simply specify <code class="inline-code">"model": "auto"</code> in your API requests:</p>
                    <div class="code-block-wrapper mt-2">
                        <pre><code class="language-json">{
  "model": "auto",
  "messages": [
    {"role": "user", "content": "Analyze this image: [image data]"}
  ]
}</code></pre>
                        <button class="copy-button">Copy</button>
                    </div>
                    <p class="mt-2">The system will automatically route to a model that supports images, even if you don't know which models are available.</p>
                </div>
            </div>
        </div>
        
        <!-- User Management Section -->
        <div id="user-management" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üë§ User & Key Management</h2>
            <div class="space-y-4 text-current">
                <p>Control who can access your AI models and how.</p>
                <ul class="list-disc list-inside space-y-3 pl-4">
                    <li><strong>User Accounts:</strong> Create separate user accounts to logically group API keys. This is useful for organizing keys by team, project, or application.</li>
                    <li><strong>API Keys:</strong> From a user's "Manage Keys" page, you can create multiple keys. Each key gets a descriptive name and a unique prefix for easy identification in logs.</li>
                    <li><strong>Key Lifecycle:</strong>
                        <ul class="list-['-_'] list-inside pl-4 mt-2">
                            <li><strong>Disable/Enable:</strong> Temporarily turn a key on or off without deleting it.</li>
                            <li><strong>Revoke:</strong> Permanently and irreversibly invalidate a key. This is a security measure for lost or compromised keys.</li>
                        </ul>
                    </li>
                    <li><strong>Per-Key Rate Limits:</strong> If Redis is configured, you can override the global rate limit for specific keys, allowing you to give higher or lower priority to certain applications.</li>
                </ul>
            </div>
        </div>

        <!-- Playgrounds & Benchmarking Section -->
        <div id="playgrounds" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üß™ Playgrounds & Benchmarking: Test Your Models</h2>
            <div class="space-y-8 text-current">
                <p>The playgrounds are powerful tools for interacting with and evaluating your models directly within the UI.</p>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Chat Playground</h3>
                    <p>This is your interactive command center for testing conversational models.</p>
                    <ul class="list-disc list-inside space-y-2 mt-3 pl-4">
                        <li><strong>Model Selection:</strong> Choose from any available model, including the <code class="inline-code">"auto"</code> model for intelligent routing. The model selector is searchable, making it easy to find models among hundreds of options.</li>
                        <li><strong>Real-time Interaction:</strong> Chat with any available model and see responses stream in token by token.</li>
                        <li><strong>OpenRouter Credits Display:</strong> When using OpenRouter servers, the playground displays your account credits (total purchased, used, and remaining) in real-time. This helps you monitor usage and budget.</li>
                        <li><strong>Multi-modal Support:</strong>
                            <ul class="list-['-_'] list-inside pl-4 mt-2">
                                <li>**Images:** Simply paste an image into the chat box or use the image attach button.</li>
                                <li>**Documents:** Use the document attach button to upload text-based files (<code class="inline-code">.txt</code>, <code class="inline-code">.py</code>, <code class="inline-code">.md</code>, etc.). Their content will be automatically included in your prompt, perfect for asking questions about code or text.</li>
                            </ul>
                        </li>
                        <li><strong>System Prompts:</strong> Use the settings icon (<svg class="w-4 h-4 inline" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10.325 4.317c.426-1.756 2.924-1.756 3.35 0a1.724 1.724 0 002.573 1.066c1.543-.94 3.31.826 2.37 2.37a1.724 1.724 0 001.065 2.572c1.756.426 1.756 2.924 0 3.35a1.724 1.724 0 00-1.066 2.573c.94 1.543-.826 3.31-2.37 2.37a1.724 1.724 0 00-2.572 1.065c-.426 1.756-2.924 1.756-3.35 0a1.724 1.724 0 00-2.573-1.066c-1.543.94-3.31-.826-2.37-2.37a1.724 1.724 0 00-1.065-2.572c-1.756-.426-1.756-2.924 0-3.35a1.724 1.724 0 001.066-2.573c-.94-1.543.826-3.31 2.37-2.37.996.608 2.296.07 2.572-1.065z"></path><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z"></path></svg>) to set a system prompt, defining the model's persona or rules. We've included powerful presets like "Chain of Thought" and "Image Bounding Box Detection".</li>
                        <li><strong>Advanced Controls:</strong>
                            <ul class="list-['-_'] list-inside pl-4 mt-2">
                                <li><strong>Thinking:</strong> Enable extended reasoning/chain-of-thought for models that support it.</li>
                                <li><strong>Annotate:</strong> Enable image annotation capabilities for vision models.</li>
                                <li><strong>Verbosity:</strong> Control the level of detail in responses.</li>
                                <li><strong>Web Search:</strong> Toggle automatic web search integration (see Web Search section below).</li>
                            </ul>
                        </li>
                        <li><strong>Add Message:</strong> Use the "+" button to manually add user or AI messages to the conversation, useful for testing specific scenarios or editing conversation flow.</li>
                        <li><strong>Code Block Actions:</strong> Hover over any code block in a response to reveal "Copy" and "Save" buttons. The save button will automatically suggest a file extension based on the language (e.g., <code class="inline-code">.py</code> for Python).</li>
                        <li><strong>Message Controls:</strong> Hover over any message to Copy, Edit, Delete, or Regenerate. Editing a message forks the conversation from that point.</li>
                        <li><strong>Import/Export:</strong> Save your entire chat history to a JSON file or load a previous conversation.</li>
                    </ul>
                </div>

                <div>
                    <h3 class="text-xl font-semibold mb-2">Embedding Playground</h3>
                    <p>This tool helps you visually understand how different embedding models work. It answers the question: "Does my model group similar concepts together?"</p>
                    <ul class="list-disc list-inside space-y-2 mt-3 pl-4">
                        <li><strong>How it Works:</strong> You define groups of related words ("concepts"). The tool gets the vector embeddings for each text and uses PCA to project them into a 2D graph.</li>
                        <li><strong>Interpreting the Results:</strong> Texts with similar meanings should appear clustered together. Well-defined, tight clusters indicate that the model has a good grasp of semantic similarity.</li>
                        <li><strong>Benchmarks:</strong> Use pre-built benchmarks, create your own in the UI, or load/save them as JSON files. Any <code class="inline-code">.json</code> file you add to the <code class="inline-code">benchmarks/</code> folder will automatically appear in the "Load Pre-built" list.</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <!-- Web Search Section -->
        <div id="web-search" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üåê Web Search Integration</h2>
            <div class="space-y-6 text-current">
                <p>The proxy includes intelligent web search capabilities that automatically enhance chat requests with current information when needed.</p>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">How It Works</h3>
                    <p>When web search is enabled (via the toggle in Chat Playground or in Settings), the system uses a sophisticated decision matrix to determine if a query needs live internet data:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li><strong>Automatic Detection:</strong> The system analyzes your message for time-sensitive keywords and patterns (e.g., "current price", "latest news", "today's weather").</li>
                        <li><strong>Intelligent Scoring:</strong> Uses a scoring system that adds points for time-sensitive indicators and subtracts points for general knowledge queries.</li>
                        <li><strong>Smart Triggering:</strong> Only triggers web search when the score exceeds a threshold, avoiding unnecessary API calls for questions that can be answered from the model's training data.</li>
                        <li><strong>Seamless Integration:</strong> Search results are automatically included in the context sent to the model, allowing it to provide current, accurate information.</li>
                    </ul>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Search Engines</h3>
                    <p>The system supports multiple search backends with automatic fallback:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li><strong>SearXNG (Recommended):</strong> Self-hosted, privacy-focused metasearch engine. Configure the URL in Settings (default: <code class="inline-code">http://localhost:7019</code>).</li>
                        <li><strong>Ollama Cloud Search:</strong> Automatic fallback if SearXNG is unavailable. Requires an Ollama API key (free tier available). Configure in Settings.</li>
                    </ul>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Using Web Search</h3>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li><strong>In Chat Playground:</strong> Toggle the "Web Search" button in the header. When enabled, queries that need current information will automatically trigger a search.</li>
                        <li><strong>In API Requests:</strong> Enable proxy-wide web search in Settings. The system will automatically detect and enhance time-sensitive queries.</li>
                        <li><strong>Manual Search:</strong> Visit <code class="inline-code">/search?q=your+query</code> in your browser or use the JSON API: <code class="inline-code">/api/v1/search?q=your+query&format=json</code></li>
                    </ul>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Configuration</h3>
                    <p>Configure web search settings in the <a href="{{ url_for('admin_settings') }}" class="font-semibold text-[var(--color-primary-600)] hover:underline">Settings</a> page:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li><strong>SearXNG URL:</strong> Set the URL of your SearXNG instance (e.g., <code class="inline-code">http://localhost:7019</code>).</li>
                        <li><strong>Ollama API Keys:</strong> Configure your Ollama cloud search API keys for fallback.</li>
                        <li><strong>Enable Proxy Web Search:</strong> Toggle to automatically enable web search for all API requests.</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <!-- Statistics Section -->
        <div id="statistics" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üìà Usage Statistics</h2>
            <div class="space-y-4 text-current">
                <p>Gain insights into how your models are being used. All charts and tables are exportable to PNG or CSV.</p>
                <ul class="list-disc list-inside space-y-3 pl-4">
                    <li><strong>Global Analytics:</strong> The main <a href="{{ url_for('admin_stats') }}" class="font-semibold text-[var(--color-primary-600)] hover:underline">Usage Stats</a> page shows aggregate data across all users, including requests per day, peak hours, model popularity, and server load distribution.</li>
                    <li><strong>Per-User Analytics:</strong> From the <a href="{{ url_for('admin_users') }}" class="font-semibold text-[var(--color-primary-600)] hover:underline">User Management</a> page, click "View Usage" for any user to see the same set of detailed charts filtered specifically for them.</li>
                    <li><strong>Sortable Tables:</strong> The tables on the statistics and user management pages are sortable. Just click on a column header to reorder the data.</li>
                </ul>
            </div>
        </div>

        <!-- OpenAI Compatibility Section -->
        <div id="openai-compat" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üîå OpenAI-Compatible API</h2>
            <div class="space-y-6 text-current">
                <p>The proxy provides full OpenAI-compatible endpoints, allowing you to use it as a drop-in replacement for OpenAI's API. This makes it compatible with hundreds of applications, libraries, and frameworks that expect OpenAI's API format.</p>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Supported Endpoints</h3>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li><strong><code class="inline-code">/v1/chat/completions</code>:</strong> Chat completions endpoint (primary endpoint for most applications).</li>
                        <li><strong><code class="inline-code">/v1/completions</code>:</strong> Legacy text completions endpoint (automatically converted to chat format).</li>
                        <li><strong><code class="inline-code">/v1/embeddings</code>:</strong> Text embeddings endpoint.</li>
                        <li><strong><code class="inline-code">/v1/models</code>:</strong> List available models.</li>
                    </ul>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Using with OpenAI Clients</h3>
                    <p>You can use the proxy with any OpenAI-compatible client by simply changing the base URL:</p>
                    <div class="code-block-wrapper mt-2">
                        <pre><code class="language-python">from openai import OpenAI

# Point client to your proxy instead of OpenAI
client = OpenAI(
    api_key="op_prefix_secret",  # Your proxy API key
    base_url="http://127.0.0.1:8080"  # Your proxy URL
)

# Use exactly like OpenAI's API
response = client.chat.completions.create(
    model="llama3",  # or "auto" for intelligent routing
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)</code></pre>
                        <button class="copy-button">Copy</button>
                    </div>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Auto Model Support</h3>
                    <p>The <code class="inline-code">"auto"</code> model works with OpenAI-compatible endpoints too. Simply specify <code class="inline-code">"model": "auto"</code> and the system will intelligently route to the best model based on your request.</p>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Compatible Applications</h3>
                    <p>This makes the proxy compatible with:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li>LangChain, LangGraph, and other AI frameworks</li>
                        <li>OpenAI Python SDK and JavaScript SDK</li>
                        <li>Any application using OpenAI's API format</li>
                        <li>MSTY and other AI assistants</li>
                        <li>Custom applications expecting OpenAI endpoints</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <!-- Theming Section -->
        <div id="theming" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üé® Theming & Customization</h2>
            <div class="space-y-6 text-current">
                <p>The proxy includes a powerful theming engine that lets you customize the entire UI to match your preferences.</p>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">UI Styles</h3>
                    <p>Choose from multiple UI styles in the <a href="{{ url_for('admin_settings') }}" class="font-semibold text-[var(--color-primary-600)] hover:underline">Settings</a> page:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li><strong>Dark Glass:</strong> Modern glassmorphism design with transparency effects.</li>
                        <li><strong>Dark Flat:</strong> Clean, flat dark theme.</li>
                        <li><strong>Light Glass:</strong> Light theme with glass effects.</li>
                        <li><strong>Light Flat:</strong> Clean, flat light theme.</li>
                    </ul>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Theme Colors</h3>
                    <p>Customize the accent color with 10 built-in themes:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li>Indigo, Sky, Teal, Rose, Amber, Emerald, Fuchsia, Orange, Black, White</li>
                    </ul>
                    <p class="mt-2">Each theme provides a complete color palette that's applied consistently throughout the UI.</p>
                </div>
                
                <div>
                    <h3 class="text-xl font-semibold mb-2">Branding</h3>
                    <p>Customize your instance's branding:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li><strong>Title:</strong> Change the application title displayed in the UI.</li>
                        <li><strong>Logo:</strong> Upload a custom logo that appears in the sidebar and header.</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Security Features Section -->
        <div id="security" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üõ°Ô∏è Security Features</h2>
            <div class="space-y-8 text-current">
                <div>
                    <h3 class="text-xl font-semibold mb-2">Endpoint Blocking</h3>
                    <p>This is a critical security layer. By default, the proxy **blocks** API key holders from accessing sensitive Ollama endpoints like <code class="inline-code">/api/pull</code>, <code class="inline-code">/api/delete</code>, and <code class="inline-code">/api/create</code>. This prevents users from consuming excessive resources or modifying your backend servers.</p>
                     <div class="mt-4 p-3 rounded-md text-sm info-box">
                        <strong>Customizable:</strong> You can change the list of blocked endpoints in the <a href="{{ url_for('admin_settings') }}" class="font-semibold underline">Settings</a> page under "Endpoint Security".
                    </div>
                </div>
                <div>
                    <h3 class="text-xl font-semibold mb-2">HTTPS/SSL Encryption</h3>
                    <p>Encrypt all traffic by going to the <a href="{{ url_for('admin_settings') }}" class="font-semibold underline">Settings</a> page. You can either upload your certificate and key files directly or provide the file paths on the server. A server restart is required to apply changes.</p>
                    <p class="mt-2">For local testing, you can generate a self-signed certificate with OpenSSL:</p>
                     <div class="code-block-wrapper mt-2">
                        <pre><code class="language-bash">openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 365 -nodes -subj "/CN=localhost"</code></pre>
                        <button class="copy-button">Copy</button>
                    </div>
                </div>
                 <div>
                    <h3 class="text-xl font-semibold mb-2">IP Filtering</h3>
                    <p>In the <a href="{{ url_for('admin_settings') }}" class="font-semibold underline">Settings</a> page, you can specify comma-separated lists of IP addresses or ranges (e.g., <code class="inline-code">192.168.1.0/24</code>) for the "Allowed IPs" and "Denied IPs" fields to control access to the proxy.</p>
                </div>
                 <div>
                    <h3 class="text-xl font-semibold mb-2">Rate Limiting & Brute-Force Protection</h3>
                    <p>When Redis is enabled, you can set global or per-key rate limits. The proxy also automatically blocks IPs that have too many failed admin login attempts.</p>
                </div>
                <div>
                    <h3 class="text-xl font-semibold mb-2">Encrypted API Key Storage</h3>
                    <p>All API keys (both user API keys and server API keys) are stored encrypted in the database using industry-standard encryption. This protects sensitive credentials even if database access is compromised.</p>
                </div>
            </div>
        </div>
            
        <!-- Usage Examples Section -->
        <div id="examples" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üë®‚Äçüíª Usage Examples</h2>
            <div class="space-y-8">
                <div>
                    <h3 class="text-xl font-semibold mb-2">cURL</h3>
                    <div class="code-block-wrapper">
                        <pre><code class="language-bash">
curl http://127.0.0.1:8080/api/generate \
  -H "Authorization: Bearer op_prefix_secret" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3",
    "prompt": "Why is the sky blue?",
    "stream": false
  }'</code></pre>
                        <button class="copy-button">Copy</button>
                    </div>
                </div>
                 <div>
                    <h3 class="text-xl font-semibold mb-2">Python (`requests`)</h3>
                    <div class="code-block-wrapper">
                        <pre><code class="language-python">
import requests
import json

proxy_url = "http://127.0.0.1:8080/api/chat"
api_key = "op_prefix_secret"

headers = {
    "Authorization": f"Bearer {api_key}",
    "Content-Type": "application/json"
}

data = {
    "model": "llama3",
    "messages": [
        {"role": "user", "content": "Explain quantum computing simply."}
    ],
    "stream": False
}

response = requests.post(proxy_url, headers=headers, data=json.dumps(data))
print(response.json())
</code></pre>
                        <button class="copy-button">Copy</button>
                    </div>
                </div>
            </div>
        </div>

        <!-- Redis Setup Guide -->
        <div id="redis-setup" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">‚ö° Redis Setup Guide</h2>
            <div class="space-y-6 text-current">
                <div>
                    <h3 class="text-xl font-semibold mb-2">Why Do I Need Redis?</h3>
                    <p>Redis is an in-memory database that provides high-speed data access. This application uses it for two optional but important security features:</p>
                    <ul class="list-disc list-inside space-y-2 mt-2 pl-4">
                        <li><strong>API Rate Limiting:</strong> Prevents abuse by limiting how many requests a key can make in a given time.</li>
                        <li><strong>Brute-Force Protection:</strong> Temporarily locks an IP address after too many failed admin logins.</li>
                    </ul>
                    <div class="mt-4 p-3 rounded-md text-sm warning-box">
                        <strong>Note:</strong> The proxy will work perfectly without Redis, but these security features will be disabled.
                    </div>
                </div>

                <div>
                    <h3 class="text-xl font-semibold mb-2">Installation</h3>
                    <p class="mb-4">The easiest way to run Redis on any platform is with Docker.</p>
                    <div class="code-block-wrapper mt-2">
                        <pre><code class="language-bash">docker run -d --name redis-stack -p 6379:6379 --restart always redis/redis-stack:latest</code></pre>
                         <button class="copy-button">Copy</button>
                    </div>
                </div>
                 <div>
                    <h3 class="text-xl font-semibold mb-2">Configuration</h3>
                    <p>Once Redis is running, go to the <a href="{{ url_for('admin_settings') }}" class="font-semibold text-[var(--color-primary-600)] hover:underline">Settings</a> page, enter your Redis connection details, and save. The proxy will connect automatically.</p>
                </div>
            </div>
        </div>
        
        <!-- Credits Section -->
        <div id="credits" class="card-style scroll-mt-20">
            <h2 class="card-header text-2xl font-bold mb-6 pb-2">üíñ Credits & Acknowledgements</h2>
            <div class="space-y-4 text-current">
                <p>This application was developed with passion by the open-source community. It stands on the shoulders of giants and wouldn't be possible without the following incredible projects:</p>
                <ul class="list-disc list-inside space-y-2 pl-4">
                    <li><strong><a href="https://fastapi.tiangolo.com/" target="_blank" class="font-semibold text-[var(--color-primary-600)] hover:underline">FastAPI</a></strong>, <strong><a href="https://www.sqlalchemy.org/" target="_blank" class="font-semibold text-[var(--color-primary-600)] hover:underline">SQLAlchemy</a></strong>, <strong><a href="https://jinja.palletsprojects.com/" target="_blank" class="font-semibold text-[var(--color-primary-600)] hover:underline">Jinja2</a></strong>, <strong><a href="https://www.chartjs.org/" target="_blank" class="font-semibold text-[var(--color-primary-600)] hover:underline">Chart.js</a></strong>, and <strong><a href="https://tailwindcss.com/" target="_blank" class="font-semibold text-[var(--color-primary-600)] hover:underline">Tailwind CSS</a></strong>.</li>
                </ul>
                <p class="pt-4">Project built and maintained by <strong>ParisNeo</strong> with help from AI and cool developers (check the contributors list in the github page).</p>
                <p>Visit the project on <a href="https://github.com/ParisNeo/ollama_proxy_server" target="_blank" class="font-semibold text-[var(--color-primary-600)] hover:underline">GitHub</a> to contribute, report issues, or star the repository!</p>
            </div>
        </div>
    </div>

    <!-- Sticky Table of Contents -->
    <div class="w-full lg:w-1/4">
        <div class="sticky top-10">
            <div class="card-style">
                <h3 class="card-header text-lg font-bold mb-4">On this page</h3>
                <nav>
                    <ul class="space-y-2">
                        <li><a href="#getting-started" class="toc-link">Getting Started</a></li>
                        <li><a href="#dashboard" class="toc-link">The Dashboard</a></li>
                        <li><a href="#server-management" class="toc-link">Server Management</a></li>
                        <li><a href="#models-manager" class="toc-link">Models Manager & Auto-Routing</a></li>
                        <li><a href="#user-management" class="toc-link">User Management</a></li>
                        <li><a href="#playgrounds" class="toc-link">Playgrounds</a></li>
                        <li><a href="#web-search" class="toc-link">Web Search</a></li>
                        <li><a href="#openai-compat" class="toc-link">OpenAI Compatibility</a></li>
                        <li><a href="#theming" class="toc-link">Theming & Customization</a></li>
                        <li><a href="#statistics" class="toc-link">Usage Statistics</a></li>
                        <li><a href="#security" class="toc-link">Security Features</a></li>
                        <li><a href="#examples" class="toc-link">Usage Examples</a></li>
                        <li><a href="#redis-setup" class="toc-link">Redis Setup</a></li>
                        <li><a href="#credits" class="toc-link">Credits</a></li>
                    </ul>
                </nav>
            </div>
        </div>
    </div>
</div>

<script>
document.addEventListener('DOMContentLoaded', () => {
    // Copy button logic
    document.querySelectorAll('.copy-button').forEach(button => {
        button.addEventListener('click', () => {
            const codeBlock = button.previousElementSibling.querySelector('code');
            const text = codeBlock.innerText;
            
            navigator.clipboard.writeText(text).then(() => {
                const originalText = button.textContent;
                button.textContent = 'Copied!';
                setTimeout(() => {
                    button.textContent = originalText;
                }, 2000);
            }).catch(err => {
                console.error('Failed to copy text: ', err);
            });
        });
    });

    // Table of Contents scroll-spy logic
    const sections = document.querySelectorAll('div[id]');
    const tocLinks = document.querySelectorAll('.toc-link');

    const observer = new IntersectionObserver((entries) => {
        let visibleSectionId = null;
        let maxRatio = 0;
        entries.forEach(entry => {
            if (entry.isIntersecting && entry.intersectionRatio > maxRatio) {
                maxRatio = entry.intersectionRatio;
                visibleSectionId = entry.target.getAttribute('id');
            }
        });
        
        if (!visibleSectionId && entries.length > 0 && entries[0].isIntersecting) {
             visibleSectionId = entries[0].target.getAttribute('id');
        }

        if (visibleSectionId) {
             tocLinks.forEach(link => {
                link.classList.remove('active-toc');
                if (link.getAttribute('href') === `#${visibleSectionId}`) {
                    link.classList.add('active-toc');
                }
            });
        }
    }, {
        rootMargin: '-20% 0px -70% 0px',
        threshold: [0.1, 0.5, 0.9]
    });

    sections.forEach(section => {
        observer.observe(section);
    });
});
</script>
{% endblock %}
